{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7d7hkuZ-5mfz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys, time, random, copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8iBHEe_2cDz"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cEGbSUXF5mf1"
   },
   "outputs": [],
   "source": [
    "# Number of hidden layers\n",
    "N_layers = 2\n",
    "\n",
    "# Number of neurons in each hidden layers\n",
    "N_hidden_neurons = 1024\n",
    "N_input_neurons = 784\n",
    "N_output_neurons = 10\n",
    "# Training parameters\n",
    "BETA = 0.5\n",
    "epsilon = 0.5\n",
    "n_iter1 = 60\n",
    "n_iter2 = 6\n",
    "\n",
    "alpha = np.zeros(N_layers)\n",
    "a_xh1 = 0.1\n",
    "# a_h1h2 = 0.1\n",
    "a_h1y = 0.05\n",
    "\n",
    "MINI_BATCH_SIZE = 20\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgHGeUGv5mf2",
    "outputId": "55305550-053c-4e94-8b90-689470e1d6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eYGTGrKq5mf3"
   },
   "outputs": [],
   "source": [
    "def glorot_bengio_init(n_in, n_out):\n",
    "    std_dev = math.sqrt(2 / (n_in + n_out))\n",
    "    return torch.tensor(np.random.normal(0, std_dev, (n_out, n_in)))\n",
    "\n",
    "W_xh1 = glorot_bengio_init(N_input_neurons, N_hidden_neurons).to(device)\n",
    "\n",
    "# W_h1h2 = glorot_bengio_init(N_hidden_neurons, N_hidden_neurons).to(device)\n",
    "\n",
    "W_h1y = glorot_bengio_init(N_hidden_neurons, N_output_neurons).to(device)\n",
    "\n",
    "B_h1 = torch.zeros(N_hidden_neurons).to(device)\n",
    "\n",
    "# B_h2 = torch.zeros(N_hidden_neurons).to(device)\n",
    "\n",
    "B_y = torch.zeros(N_output_neurons).to(device)\n",
    "\n",
    "input_layer = torch.zeros(MINI_BATCH_SIZE, N_input_neurons).to(device)\n",
    "\n",
    "hlayer1 = torch.zeros(MINI_BATCH_SIZE, N_hidden_neurons).to(device)\n",
    "\n",
    "# hlayer2 = torch.zeros(MINI_BATCH_SIZE, N_hidden_neurons).to(device)\n",
    "\n",
    "output_layer = torch.zeros(MINI_BATCH_SIZE, N_output_neurons).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHf0OjBPp1Qp",
    "outputId": "d7a68dbb-9dca-422d-f587-6643a58f9786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 1024])\n",
      "torch.Size([1024, 784])\n",
      "torch.Size([20, 784])\n",
      "torch.Size([20, 1024])\n",
      "torch.Size([20, 10])\n"
     ]
    }
   ],
   "source": [
    "print(B_h1.shape)\n",
    "print(B_y.shape)\n",
    "print(W_h1y.shape)\n",
    "print(W_xh1.shape)\n",
    "print(input_layer.shape)\n",
    "print(hlayer1.shape)\n",
    "print(output_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OevpVzc2pmn9",
    "outputId": "e07233f8-701d-4f0b-b20c-6abbd7a636cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST('../datasets',\n",
    "                               train=True,\n",
    "                               download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "test_dataset = datasets.MNIST('../datasets',\n",
    "                              train=False,\n",
    "                              download=True,\n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset, batch_size=MINI_BATCH_SIZE, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(test_dataset, batch_size=MINI_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "numbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "integer_encoded = label_encoder.fit_transform(numbers)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "x_train_batches = []\n",
    "y_train_batches = []\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "    x_train = data.view(-1, 784)\n",
    "\n",
    "    y_train = torch.tensor(onehot_encoded[target])\n",
    "\n",
    "    x_train = x_train / 255.0\n",
    "\n",
    "    x_train_batches.append(x_train)\n",
    "    y_train_batches.append(y_train)\n",
    "\n",
    "print(y_train_batches)\n",
    "\n",
    "x_train_batches = torch.stack(x_train_batches, 0).to(device)\n",
    "y_train_batches = torch.stack(y_train_batches, 0).to(device)\n",
    "\n",
    "x_test_batches = []\n",
    "y_test_batches = []\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "\n",
    "    x_test = data.view(-1, 784)\n",
    "\n",
    "    y_test = torch.tensor(onehot_encoded[target])\n",
    "\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    x_test_batches.append(x_test)\n",
    "    y_test_batches.append(y_test)\n",
    "\n",
    "x_test_batches = torch.stack(x_test_batches, 0).to(device)\n",
    "y_test_batches = torch.stack(y_test_batches, 0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "kwd9bwtWG38r",
    "outputId": "b6039b1f-5725-4857-8dae-68fac714b6d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = x_train_batches[0][0].reshape(28, 28).cpu()\n",
    "print(pixels.shape)\n",
    "plt.imshow(pixels, cmap = 'plasma')\n",
    "plt.colorbar()\n",
    "print(y_train_batches[0][0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4gs8JVTE2Uym"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    # a = torch.clamp(x, 0, 1).to(device)\n",
    "    torch.nn.functional.relu(x, inplace = True).to(device)\n",
    "    return x.double()\n",
    "\n",
    "def del_relu(x):\n",
    "    a = torch.nn.functional.relu(x, inplace = False).to(device)\n",
    "    slope = (x == a).double()\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c7tt6gLtqR-",
    "outputId": "7f807ec7-bafd-4ee0-9d4a-211c158ae385"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = -1*torch.ones((20, 500)).to(device)\n",
    "del_relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLaRlM9m2SsY",
    "outputId": "72766356-6b17-4d3e-d727-c106878a0cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1024])\n",
      "torch.Size([20, 1024])\n"
     ]
    }
   ],
   "source": [
    "t = torch.zeros(MINI_BATCH_SIZE, hlayer1.shape[1]).to(device)\n",
    "print(t.shape)\n",
    "# hard_sigmoid(t).shape\n",
    "\n",
    "# x = torch.tensor([1])\n",
    "print(del_relu(t).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-eYC6ECIGJn",
    "outputId": "7e404acf-ac46-4280-ab6f-42047d5656cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_batches[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMQjZyffLg6V",
    "outputId": "fb9e78f4-8639-4884-8771-cb4eaf53d643"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 1],\n",
       "        [1, 2, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 1], [1, 2, 1]])\n",
    "b = torch.tensor([[1, 2, 1], [1, 1, 1]])\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AivNIXdf42b_"
   },
   "outputs": [],
   "source": [
    "# MINI NN\n",
    "mbatch = 2\n",
    "mW_xh1 = torch.ones(4, 2).double().to(device)\n",
    "\n",
    "mW_h1y = torch.ones(2, 4).double().to(device)\n",
    "\n",
    "mB_h1 = torch.ones(4).double().to(device) * 0.25\n",
    "\n",
    "mB_y = torch.ones(2).double().to(device) * 0.2\n",
    "\n",
    "minput_layer = torch.ones(mbatch, 2).double().to(device) * 0.5\n",
    "\n",
    "mhlayer1 = torch.ones(mbatch, 4).double().to(device)\n",
    "\n",
    "moutput_layer = torch.ones(mbatch, 2).double().to(device) * 0.5\n",
    "\n",
    "my_hat = torch.zeros(mbatch, 2).double().to(device)\n",
    "my_hat[0][0] = 1\n",
    "my_hat[1][1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AluAKRYp7-SI",
    "outputId": "3ad9a8ba-649e-409d-e1c1-a1d5f57b39b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# print(mW_h1y) # N_op * N_curr\n",
    "# print(moutput_layer) # batch * N_op\n",
    "# print(mB_h1)\n",
    "# print(mB_h1.repeat(mbatch, 1).shape)\n",
    "print(mhlayer1)\n",
    "# print(minput_layer)\n",
    "# print((my_hat - moutput_layer)* 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Q9jg3rtl7FF",
    "outputId": "0d76d9cd-2612-4d80-f542-0c6831da17ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(mhlayer1, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxfD3keNfQsc",
    "outputId": "9c0be51a-8bec-45fe-b4ce-9c8d6a0c143e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(relu(mhlayer1.t()), relu(minput_layer)) / mbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9d0hr5GYsmx",
    "outputId": "a2c5e77f-c5c3-4152-f961-e2a39d199c52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.5000, 3.0000, 3.5000], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3, 4],\n",
    "                  [1, 1, 3, 3]]).double()\n",
    "b = torch.tensor([[1],\n",
    "                  [-1],\n",
    "                  [2],\n",
    "                  [-2]])\n",
    "# print(a.shape, b.shape)\n",
    "# a * b.t()\n",
    "torch.mean(a, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_sc7nnWV7QW",
    "outputId": "df5dfd46-e4b3-4bdd-da0e-5ff431c976f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2500, 1.2500, 1.2500, 1.2500],\n",
       "        [1.2500, 1.2500, 1.2500, 1.2500]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.mm(relu(minput_layer), mW_xh1.t()) + mB_h1.repeat(mbatch, 1)) * del_relu(mhlayer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCac6vC89U83",
    "outputId": "5cddce2d-d733-4b8a-a85f-e09f1abafec4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(relu(moutput_layer), mW_h1y).shape # batch * curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xECR_pANWrdB",
    "outputId": "68698a28-219b-461b-e871-f2c5b4eb7f41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhlayer1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vBsoVNC05mf4"
   },
   "outputs": [],
   "source": [
    "def ds_dt(W_prev, layer_prev, W_next, layer_next, N_layer, layer, B, y_hat, is_op, beta, m_batch = MINI_BATCH_SIZE):\n",
    "\n",
    "    dc_ds = torch.zeros(m_batch, N_layer).to(device) # layer at a time\n",
    "\n",
    "    de_ds = (torch.mm(relu(layer_prev), W_prev.t()) + B.repeat(m_batch, 1)).to(device)\n",
    "\n",
    "    if is_op == 1:\n",
    "        dc_ds = beta * (y_hat - layer)\n",
    "    else:\n",
    "        de_ds += torch.mm(relu(layer_next), W_next)\n",
    "\n",
    "    de_ds *= del_relu(layer)\n",
    "    de_ds -= layer\n",
    "\n",
    "    return de_ds + dc_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "txcTk1OAz2tA"
   },
   "outputs": [],
   "source": [
    "# ds_dt(mW_xh1, minput_layer, mW_h1y, moutput_layer, mhlayer1.shape[1], mhlayer1, mB_h1, my_hat, 0, BETA, mbatch)\n",
    "# ds_dt(mW_h1y, mhlayer1, None, None, moutput_layer.shape[1], moutput_layer, mB_y, my_hat, 1, BETA, mbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5TALElY5mf5",
    "outputId": "ad148eac-7edf-4418-891d-53c3fa6b238b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000, 20, 784])\n",
      "torch.Size([3000, 20, 10])\n",
      "torch.Size([500, 20, 784])\n",
      "torch.Size([500, 20, 10])\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "# print(np.max(x_train[100]))\n",
    "print(x_train_batches.shape)\n",
    "print(y_train_batches.shape)\n",
    "print(x_test_batches.shape)\n",
    "print(y_test_batches.shape)\n",
    "print(len(x_train_batches))\n",
    "# print(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHDDblxCwPjb",
    "outputId": "f6583f23-388d-435d-94bc-5f523ee5ee87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw_xh1 = torch.zeros(W_xh1.shape).to(device)\n",
    "# dw_h1h2 = torch.zeros(W_h1h2.shape).to(device)\n",
    "dw_h1y = torch.zeros(W_h1y.shape).to(device)\n",
    "\n",
    "db_h1 = torch.zeros(B_h1.shape).to(device)\n",
    "# db_h2 = torch.zeros(B_h2.shape).to(device)\n",
    "db_y = torch.zeros(B_y.shape).to(device)\n",
    "\n",
    "db_h1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4b6TKYnX7s7",
    "outputId": "3ab5dce4-3442-464e-d132-5e04dcd013a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# SANITY CHECK\n",
    "print(x_train_batches.device)\n",
    "print(W_xh1.device)\n",
    "print(hlayer1.device)\n",
    "print(dw_xh1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "If1EYJmho8Es"
   },
   "outputs": [],
   "source": [
    "# output_layer = copy.deepcopy(y_train_batches[13])\n",
    "# print(y_train_batches[13][11].argmax())\n",
    "# output_layer[11] = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "# output_layer[12] = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "# print(output_layer[11].argmax())\n",
    "# c = 0\n",
    "# for idx, element in enumerate(y_train_batches[13]):\n",
    "#     c += int((element.argmax() == output_layer[idx].argmax()))\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eSet7V6IgCfT"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "total_iterations = len(x_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gTBt-rmyU6vm"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "referenced_widgets": [
      "07846b6c1ecc4490900700cda0a31cef",
      "55448fc97ad241f6932c3cd8e691c234",
      "ca49ad2594f44b0191696c1314ca4e46",
      "2ca1cb44e9b94644bbd6ce4bbf2eafcf",
      "ac4e9b9568794b33916c70b0c79eb1b5",
      "55316314997944869857e98be9473184",
      "572013214f5b467c917ed6356eb334af",
      "2fcc704e762b47b8aa92724e603d1471",
      "8814d3db52af44509a62e47f17030396",
      "5d3e7212f66e4151a66414f59bd28fa8",
      "aa649a5ad4114cfda49c83dd2a75430d"
     ]
    },
    "id": "O2NRhdeI5mf6",
    "outputId": "9f74f661-db12-4ee2-bc6c-f55fa013075f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running epoch  0\n",
      "Average training time per batch in epoch  0  =  0.08016673978169786\n",
      "Testing model on training data\n",
      "Correct  1834\n",
      "Testing accuracy after epoch  0  =  18.34\n",
      "Currently running epoch  1\n",
      "Average training time per batch in epoch  1  =  0.08801979406674691\n",
      "Testing model on training data\n",
      "Correct  2883\n",
      "Testing accuracy after epoch  1  =  28.83\n",
      "Currently running epoch  2\n",
      "Average training time per batch in epoch  2  =  0.0879995553493499\n",
      "Testing model on training data\n",
      "Correct  4010\n",
      "Testing accuracy after epoch  2  =  40.1\n",
      "Currently running epoch  3\n",
      "Average training time per batch in epoch  3  =  0.0879149566491445\n",
      "Testing model on training data\n",
      "Correct  4998\n",
      "Testing accuracy after epoch  3  =  49.980000000000004\n",
      "Currently running epoch  4\n",
      "Average training time per batch in epoch  4  =  0.0881147816181184\n",
      "Testing model on training data\n",
      "Correct  5080\n",
      "Testing accuracy after epoch  4  =  50.8\n",
      "Currently running epoch  5\n",
      "Average training time per batch in epoch  5  =  0.0881261618932088\n",
      "Testing model on training data\n",
      "Correct  5436\n",
      "Testing accuracy after epoch  5  =  54.36\n",
      "Currently running epoch  6\n",
      "Average training time per batch in epoch  6  =  0.0880287339687347\n",
      "Testing model on training data\n",
      "Correct  5656\n",
      "Testing accuracy after epoch  6  =  56.56\n",
      "Currently running epoch  7\n"
     ]
    }
   ],
   "source": [
    "start_total = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_time = 0\n",
    "\n",
    "    # Training\n",
    "\n",
    "    print(\"Currently running epoch \", epoch)\n",
    "\n",
    "    for batch_index, batch in enumerate(x_train_batches):\n",
    "        start = time.time()\n",
    "\n",
    "        # Forward Pass\n",
    "\n",
    "        input_layer = batch\n",
    "\n",
    "        hlayer1.zero_()\n",
    "        output_layer.zero_()\n",
    "\n",
    "        dw_xh1.zero_()\n",
    "        dw_h1y.zero_()\n",
    "\n",
    "        db_h1.zero_()\n",
    "        db_y.zero_()\n",
    "\n",
    "        for iter in range(n_iter1):\n",
    "            hlayer1 += epsilon * ds_dt(W_xh1, input_layer, W_h1y, output_layer, hlayer1.shape[1], hlayer1, B_h1, None, 0, 0)\n",
    "            # hlayer1 = torch.clamp(hlayer1, 0, 1).double()\n",
    "\n",
    "            output_layer += epsilon * ds_dt(W_h1y, hlayer1, None, None, output_layer.shape[1], output_layer, B_y, y_train_batches[batch_index], 1, 0)\n",
    "            # output_layer = torch.clamp(output_layer, 0, 1).double()\n",
    "\n",
    "        # Collect activations\n",
    "        dw_xh1 -= torch.mm(relu(hlayer1.t()), relu(input_layer)) # mean across batches not done\n",
    "\n",
    "        dw_h1y -= torch.mm(relu(output_layer.t()), relu(hlayer1))\n",
    "\n",
    "        db_y -= torch.mean(output_layer, dim = 0) # mean across batches done\n",
    "\n",
    "        db_h1 -= torch.mean(hlayer1, dim = 0)\n",
    "\n",
    "        # Backward Pass\n",
    "        for iter in range(n_iter2):\n",
    "\n",
    "            hlayer1 += epsilon * ds_dt(W_xh1, input_layer, W_h1y, output_layer, hlayer1.shape[1], hlayer1, B_h1, None, 0, BETA)\n",
    "            # hlayer1 = torch.clamp(hlayer1, 0, 1).double()\n",
    "\n",
    "            output_layer += epsilon * ds_dt(W_h1y, hlayer1, None, None, output_layer.shape[1], output_layer, B_y, y_train_batches[batch_index], 1, BETA)\n",
    "            # output_layer = torch.clamp(output_layer, 0, 1).double()\n",
    "\n",
    "        # Collect activations\n",
    "\n",
    "        dw_xh1 += torch.mm(relu(hlayer1.t()), relu(input_layer)) # mean across batches not done\n",
    "\n",
    "        dw_h1y += torch.mm(relu(output_layer.t()), relu(hlayer1))\n",
    "\n",
    "        db_y += torch.mean(output_layer, dim = 0) # mean across batches done\n",
    "\n",
    "        db_h1 += torch.mean(hlayer1, dim = 0)\n",
    "\n",
    "        # Update weights only after each minibatch\n",
    "\n",
    "        W_h1y += a_h1y * (dw_h1y / (MINI_BATCH_SIZE * BETA))\n",
    "\n",
    "        W_xh1 += a_xh1 * (dw_xh1 / (MINI_BATCH_SIZE * BETA))\n",
    "\n",
    "        B_y += a_h1y * (db_y / BETA)\n",
    "\n",
    "        B_h1 += a_xh1 * (db_h1 / BETA)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        avg_time += ((end - start - avg_time) / (batch_index + 1))\n",
    "\n",
    "    print(\"Average training time per batch in epoch \", epoch, \" = \", avg_time)\n",
    "\n",
    "    print(\"Testing model on training data\")\n",
    "\n",
    "    # TRAINING ERROR\n",
    "\n",
    "    c = 0\n",
    "    for test_index, test_batch_y in enumerate(y_test_batches):\n",
    "        # Forward Pass\n",
    "\n",
    "        input_layer = x_test_batches[test_index]\n",
    "\n",
    "        hlayer1.zero_()\n",
    "        output_layer.zero_()\n",
    "\n",
    "        for iter in range(n_iter1):\n",
    "            hlayer1 += epsilon * ds_dt(W_xh1, input_layer, W_h1y, output_layer, hlayer1.shape[1], hlayer1, B_h1, None, 0, 0)\n",
    "\n",
    "            output_layer += epsilon * ds_dt(W_h1y, hlayer1, None, None, output_layer.shape[1], output_layer, B_y, test_batch_y, 1, 0)\n",
    "\n",
    "        for idx, element in enumerate(test_batch_y):\n",
    "            c += int((element.argmax() == output_layer[idx].argmax()))\n",
    "\n",
    "    print(\"Correct \", c)\n",
    "    acc = c / (MINI_BATCH_SIZE * len(y_test_batches))\n",
    "    print(\"Testing accuracy after epoch \", epoch, \" = \", acc*100)\n",
    "\n",
    "\n",
    "total_time = time.time() - start_total\n",
    "print(\"Total Time \",total_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4h-gSIo5Kld"
   },
   "source": [
    "aaaaaa/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trr_J-2LYY5Y"
   },
   "source": [
    "bold text# New Section"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07846b6c1ecc4490900700cda0a31cef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_55448fc97ad241f6932c3cd8e691c234",
       "IPY_MODEL_ca49ad2594f44b0191696c1314ca4e46",
       "IPY_MODEL_2ca1cb44e9b94644bbd6ce4bbf2eafcf"
      ],
      "layout": "IPY_MODEL_ac4e9b9568794b33916c70b0c79eb1b5"
     }
    },
    "2ca1cb44e9b94644bbd6ce4bbf2eafcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d3e7212f66e4151a66414f59bd28fa8",
      "placeholder": "​",
      "style": "IPY_MODEL_aa649a5ad4114cfda49c83dd2a75430d",
      "value": " 1182/? [01:12&lt;00:00, 16.19it/s]"
     }
    },
    "2fcc704e762b47b8aa92724e603d1471": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "55316314997944869857e98be9473184": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55448fc97ad241f6932c3cd8e691c234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55316314997944869857e98be9473184",
      "placeholder": "​",
      "style": "IPY_MODEL_572013214f5b467c917ed6356eb334af",
      "value": "Progress: "
     }
    },
    "572013214f5b467c917ed6356eb334af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d3e7212f66e4151a66414f59bd28fa8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8814d3db52af44509a62e47f17030396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa649a5ad4114cfda49c83dd2a75430d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ac4e9b9568794b33916c70b0c79eb1b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "ca49ad2594f44b0191696c1314ca4e46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fcc704e762b47b8aa92724e603d1471",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8814d3db52af44509a62e47f17030396",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
